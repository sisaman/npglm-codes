\section{Experiments}\label{sec:results}

We have conducted extensive experiments on both synthetic and real-world datasets to assess the effectiveness of \npglm.

\subsection{Experiments on synthetic data}
We use synthetic data to verify the correctness of \npglm and its learning algorithm. Since \npglm is a non-parametric method, we generate synthetic data using various parametric models with previously known random parameters, and evaluate how well \npglm can learn the parameters and the underlying distribution of the generated data.

\descr{Experiment Setup.}
We consider generalized linear models of two widely used distributions for event-time modeling, Rayleigh and Gompertz, as the ground truth models for generating synthetic data. Algorithm~\ref{alg:syn} is used to generate a total of $N$ data samples with $d$-dimensional feature vectors, consisting $N_o$ non-censored (observed) samples and remaining $N_c=N-N_o$ censored ones. For all synthetic experiments, we generate 10-dimensional feature vectors ($d=10$) and set $g(\mb{w}^T\mb{x})=\exp(\mb{w}^T\mb{x})$. We repeat every experiment 100 times and report the average.

\begin{algorithm}[t]
	\small
	\SetAlgoLined
	\KwIn{The number of observed samples $N_o$, the number of censored samples $N_c$, the dimension of the feature vectors $d$, and the desired distribution $dist$}
	\KwOut{Synthetically generated data $\mb{X}_{N\times d}$, $\mb{y}_{N\times1}$, and $\mb{t}_{N\times1}$.}
	$N\leftarrow N_o+N_c$\;
	Draw a weight vector $\mb{w}\sim\mathcal{N}(0,\mb{I}_d)$, where $\mb{I}_d$ is the $d$-dimensional identity matrix\;
	Draw scalar intercept $b\sim\mathcal{N}(0,1)$\;
	\For{$i\leftarrow1$ to $N$}{
		Draw feature vector $\mb{x}_i\sim\mathcal{N}(0,\mb{I}_d)$\;
		Set distribution parameter $\alpha_i\leftarrow\exp(\mb{w}^T\mb{x}_i+b)$\;
		\uIf{$dist == Rayleigh$}{
			Draw $t_i\sim\alpha_i~t\exp\{-0.5\alpha_it^2\}$\;
		}
		\uElseIf{$dist == Gompertz$}{
			Draw $t_i\sim\alpha_i~e^t\exp\{-\alpha_i(e^t-1)\}$\;
		}
	}
	
	Sort pairs $(\mb{x}_i,t_i)$ by $t_i$ in ascending order\;
	
	\For{$i\leftarrow1$ to $N_o$}{
		$y_i\leftarrow1$\;
	}
	\For{$i\leftarrow(N_o+1)$ to $N$}{
		$y_i\leftarrow0$\;
	}
	\caption{Synthetic dataset generation algorithm.}
	\label{alg:syn}
\end{algorithm}


\descr{Experiment Results.}
Since \npglm's learning is done in an iterative manner, we first analyzed whether this algorithm converges as the number of iterations increase. We recorded the log-likelihood of \npglm, averaged over the number of training samples $N$ in each iteration. We repeated this experiment for $N\in\{1000,2000,3000\}$ with a fixed censoring ratio of 0.5, which means half of the samples are censored. The result is depicted in Fig.~\ref{fig:syn-cvg-n}. We can see that the algorithm successfully converges with a rate depending on the underlying distribution. For the case of Rayleigh, it requires about 100 iterations to converge but for Gompertz, this reduces to about 30. Also, we see that using more training data results in achieving more log-likelihood as expected.



In Fig.~\ref{fig:syn-cvg-c}, we fixed $N=1000$ and performed the same experiment this time using different censoring ratios. According to the figure, we see that by increasing the censoring ratio, the convergence rate increases. This is because \npglm infers the values of $H(t)$ for all $t$ in the observation window. Therefore, as the censoring ratio increases, the observation window is decreased, so \npglm has to infer a fewer number of parameters, leading to a faster convergence. Note that as opposed to Fig.~\ref{fig:syn-cvg-n}, here a higher log-likelihood doesn't necessarily indicate a better fit, due to the likelihood marginalization we get by the censored samples.


Next, we analyzed the performance of \npglm in terms of the achieved log-likelihood on a separate test dataset by gradually increasing the number of training samples under different censoring ratios. We put away a number of 100K synthetically generated test data samples and trained \npglm with a training dataset of size ranging from 100 to 900. In each step, we calculated the average log-likelihood of the trained model on the test. We repeated this experiment using different censoring ratios. The result is depicted in Fig.~\ref{fig:syn-logl-n}. According to the figure, the log-likelihood achieved on the test dataset gradually rises with the increase in the number of training samples. That is because using more training samples could result in a better estimate of the parameters by which the test data samples are generated.

In another experiment, we evaluated how good \npglm can infer the parameters used to generate the synthetic data. To this end, we varied the number of training samples $N$ and measured the mean absolute error (MAE) between the learned weight vector $\hat{\mathbf{w}}$ and the ground truth. Fig.~\ref{fig:syn-mae-n} illustrates the result for different censoring ratios. It can be seen that as the number of training samples increases, the MAE gradually decreases. The other point to notice is that more censoring ratio results in higher error due to the information loss we get by censoring.



Finally, we investigated whether censored samples are informative or not. For this purpose, we fixed the number of observed samples $N_o$ and changed the number of censored samples from 0 to 200. We measure the MAE between the learned $\mb{w}$ and the ground truth for $N_o\in\{200,300,400\}$. The result is shown in Fig.~\ref{fig:syn-mae-c}. It clearly demonstrates that adding more censored samples causes the MAE to dwindle up to an extent, after which we get no substantial improvement. This threshold is dependent on the underlying distribution. In this case, for Rayleigh and Gompertz it is about 80 and 120, respectively.

\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		ymax=2.5,
		ymin=1.2,
		xmin=0,
		xmax=200,
		%ytick={0.08,0.10,...,0.2},
		xtick={20,60,...,180},
		restrict x to domain=0:200,
		legend entries={${\tiny N=1000}$, $N=2000$, $N=3000$},
		]
		\addplot[color=cyan,  thick, dashed] table{results/cvg_ray_1000.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_ray_2000.txt};
		\addplot[color=purple,thick] table{results/cvg_ray_3000.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		ymax=2.3,
		%ymin=0.06,
		xmin=0,
		xmax=60,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,20,...,50},
		restrict x to domain=0:100,
		legend entries={$N=1000$, $N=2000$, $N=3000$},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_gom_1000.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_gom_2000.txt};
		\addplot[color=purple,thick] table{results/cvg_gom_3000.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{Convergence of \npglm's average log-likelihood ($\log\mathcal{L}$) for different number of training samples ($N$). Censoring ratio has been set to 0.5.}
	\label{fig:syn-cvg-n}
\end{figure}
\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -8 pt,
		%ymax=0.2,
		ymin=-2,
		xmin=0,
		xmax=100,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,30,...,90},
		restrict x to domain=0:200,
		legend entries={5\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_ray_5.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_ray_25.txt};
		\addplot[color=purple,thick] table{results/cvg_ray_50.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		%ymax=0.2,
		%ymin=0.06,
		xmin=0,
		xmax=60,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,20,...,50},
		restrict x to domain=0:60,
		legend entries={5\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_gom_5.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_gom_25.txt};
		\addplot[color=purple,thick] table{results/cvg_gom_50.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{Convergence of \npglm's average log-likelihood ($\log\mathcal{L}$) for different censoring ratios with 1K samples.}
	\label{fig:syn-cvg-c}
\end{figure}

\begin{figure}[t]
	\hfill  
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$ N $,
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		%xticklabel style={rotate=90},
		%		ymax=0.35,
		xmin=0,
		xmax=1000,
		%		ytick={0.05,0.10,...,0.35},
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		legend entries={0\% censoring, 5\% censoring, 10\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/logl_ray_0.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/logl_ray_5.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/logl_ray_10.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$ N $,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		%		ymax=0.22,
		%		ymin=0.01,
		xmin=0,
		xmax=1000,
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		%		ytick={0.04,0.07,...,0.21},
		legend entries={0\% censoring, 5\% censoring, 10\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/logl_gom_0.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/logl_gom_5.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/logl_gom_10.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{\npglm's achieved average log-likelihood on the separate test data vs the number of training samples ($N$) with different censoring ratios.}
	\label{fig:syn-logl-n}
\end{figure}

\begin{figure}[t]
	\hfill  
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$ N $,
		ylabel=MAE,
		ylabel shift = -4 pt,
		%xticklabel style={rotate=90},
		ymax=0.35,
		xmin=0,
		xmax=1000,
		ytick={0.05,0.10,...,0.35},
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		legend entries={0\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_ray.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_ray_25.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_ray_50.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$ N $,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.22,
		ymin=0.01,
		xmin=0,
		xmax=1000,
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		ytick={0.04,0.07,...,0.21},
		legend entries={0\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_gom.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_gom_25.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_gom_50.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{\npglm's mean absolute error (MAE) vs the number of training samples ($N$) for different censoring ratios.}
	\label{fig:syn-mae-n}
\end{figure}


\subsection{Experiments on real data}
We apply \npglm with the proposed feature set on real-world dataset to evaluate its effectiveness and compare its performance in predicting the time of link creation vis-\`a-vis different parametric models. 

\descr{Dataset.} We have used DBLP bibliographic citation network, provided by \cite{tang2008aminer}, as the real-world dataset which has both attributes of dynamicity and heterogeneity. Based on the publication venue of the papers, we extracted two networks, named \emph{dblp-db} and \emph{dblp-th}, from the original DBLP dataset. The dblp-db is composed of papers which are published in conferences or journals related to Database, Data Mining, Machine Learning, and Artificial Intelligence. Moreover, those papers that are published in venues relative to the theoretical computer science, constitute the dblp-th network. The demographic statistics of both networks is presented in Table~\ref{table:dataset}.

\begin{table}[t]
	\centering
	\caption{Properties of DBLP Bibliographic Network}
	\label{table:dataset}
	\scriptsize
	\begin{tabu} to \columnwidth {X[l] X[l] X[c] X[c]}
		\toprule
		& & \multicolumn{2}{c}{Network} \\
		\cmidrule(l){3-4}
		& Property & {dblp-db} & {dblp-th}\\
		\midrule % In-table horizontal line
		\multirow{4}{*}{\# Nodes}
		& $Author$ & 51,486 & 29,542 \\ % Content row 1
		& $Paper$ & 79,069 & 64,333 \\ % Content row 2
		& $Venue$ & 19 & 40 \\ % Content row 3
		& $Term$ & 22,567 & 18,578 \\ % Content row 3
		\midrule
		\multirow{4}{*}{\# Relations}
		& $write$ & 123,343 & 77,783 \\ % Content row 1
		& $publish$ & 39,965 & 30,732 \\ % Content row 2
		& $cite$ & 217,037 & 141,215 \\ % Content row 3
		& $mention$ & 278,257 & 206,735 \\ % Content row 3
		\bottomrule % Bottom horizontal line
	\end{tabu}
\end{table}

\descr{Experiment Setup.}
We confined the dataset to the papers which has been published between the years 1995 and 2016, and selected the authors who had published more than 5 papers in the Feature Extraction Window of each experiment. Following the method described for feature extraction in Section~\ref{sec:features}, we extracted 19 dynamic meta-path-based features. The rate parameter of features were determines using a separate validation set to get the best results. As \npglm needs the data samples sorted by their corresponding time variables, the samples were sorted according to their recorded time. Finally, since the features extracted for different meta-paths have different scales, we normalized the data using Z-Score. In all experiments, the author citation relation ($A\rightarrow P\rightarrow P\leftarrow A$) were chosen as the target relation.

To challenge the performance of \npglm, we use the generalized linear model-based framework proposed in \cite{sun2012will} with Exponential, Rayleigh, and Gompertz as distributions with different shapes, denoted as \textsc{Exp-Glm}, \textsc{Ray-Glm}, and \textsc{Gom-Glm}, respectively. We use 10-fold cross-validation and report the average results for all the experiments in this section.

\descr{Experiment Results.}
In the first set of experiments, we evaluated the prediction power of different models using different feature sets, and assessed how well they generalize in different configurations for the feature extraction window and the observation window. Under each configuration, we considered the median of the distribution $f_T(t\mid \mb{x}_{test})$ as the predicted time for that sample and then compared it to the ground truth time $t_{test}$. \emph{Mean Absolute Error} (MAE) and \emph{Mean Relative Error} (MRE) are used to measure the accuracy of the predicted values. To examine the effect of considering the dynamicity of the network on the performance of the models, we evaluated each one with two different feature sets: \emph{dynamic} and \emph{static}. Dynamic feature set is our proposed features which captures the dynamicity of the network. On the contrary, static feature set only uses the very last snapshot of the network just before the beginning of the observation window, failing to reflect the temporal dynamics of the network. 

In Table~\ref{table:results}, we set $\Phi=10$ and varied $\Omega$ within the set $\{3,6,9\}$. The MAE and MRE of all models under both dblp-db and dblp-th networks, and using both dynamic and static feature sets has been recored. We see that in both networks, \npglm using the dynamic features is superior to the other models. For instance, when $\Omega=3$, our model \npglm can obtain an MAE of 0.21 for the dblp-db dataset, which is 28.5\% lower than the MAE obtained by its closest competitor, \textsc{Exp-Glm}. As of MRE, \npglm achieves 0.16 on dblp-db, which is 25\% lower than \textsc{Exp-Glm}. 
On dblp-th, \npglm reduces the MAE and MRE by 36\% and 11\%, respectively, relative to \textsc{Exp-Glm}. Comparable results hold for other values of $\Omega$ as well. Moreover, in this table it is evident that using the dynamic features has a positive impact on the performance of all models and decreases their prediction error.

Table~\ref{table:results2} compares the MAE and MRE of different models when we set $\Omega=6$ and selected $\Phi$ from the set $\{5,10,15\}$. Again the results of all models have been obtained under both dblp-db and dblp-th networks, and using both static and dynamic feature sets. It is clear that \npglm has performed better than other baselines, even when it uses static features.
When $\Phi=15$ for example, \npglm achieved an MAE of 0.62 and an MRE of 0.35 on the dblp-db dataset, which are respectively 22\% and 14\% lower than \textsc{Exp-Glm}'s. On dblp-th, \npglm caused a 7\% cut in MAE and a 30\% cut in MRE compared to \textsc{Exp-Glm}'s results.
Here, the obtained results also show that leveraging more historical data to extract features could lead to more accurate predictions and lower error rates.

\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$N_c$,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.2,
		ymin=0.06,
		%xmin=0,
		%xmax=2100,
		ytick={0.08,0.10,...,0.2},
		xtick={0,40,...,200},
		legend entries={$N_o=200$, $N_o=300$, $N_o=400$},
		]
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_ray_200.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_ray_300.txt};
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_ray_400.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$N_c$,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.24,
		ymin=0.03,
		%xmin=0,
		%xmax=2100,
		ytick={0.06,0.09,...,0.21},
		xtick={0,40,...,200},
		legend entries={$N_o=200$, $N_o=300$, $N_o=400$},
		]
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_gom_200.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_gom_300.txt};
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_gom_400.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{\npglm's mean absolute error (MAE) vs the number of censored samples ($N_c$) for different number of observed samples ($N_o$).}
	\label{fig:syn-mae-c}
\end{figure}

\begin{figure}[t]
	\hfill  
	\subfloat[dblp-db]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\tiny,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=Absolute Error,
		ylabel=Prediction Accuracy,
		ylabel shift = -4 pt,
		%xticklabel style={rotate=90},
		ymax=1.1,
		xmin=0,
		xmax=3.5,
		ytick={0.1,0.2,...,0.9,1.0},
		xtick={0.5,1.0,...,3},
%		restrict x to domain=0:900,
		legend entries={NP-GLM, Exp-GLM, Ray-GLM, Gom-GLM},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/db_np.txt};
		\addplot[color=cyan,mark=triangle*,mark size=1.1,thick] table{results/db_exp.txt};
		\addplot[color=orange,mark=*,mark size=1.5,thick] table{results/db_ray.txt};
		\addplot[color=green,mark=diamond*,mark size=1.5,thick] table{results/db_gom.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}
	\subfloat[dblp-th]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\tiny,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=Absolute Error,
		ylabel=Prediction Accuracy,
		ylabel shift = -4 pt,
		%xticklabel style={rotate=90},
		ymax=1.1,
		xmin=0,
		xmax=3.5,
		ytick={0.1,0.2,...,0.9,1.0},
		xtick={0.5,1.0,...,3},
		%		restrict x to domain=0:900,
		legend entries={NP-GLM, Exp-GLM, Ray-GLM, Gom-GLM},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/th_np.txt};
		\addplot[color=cyan,mark=triangle*,mark size=1.1,thick] table{results/th_exp.txt};
		\addplot[color=orange,mark=*,mark size=1.5,thick] table{results/th_ray.txt};
		\addplot[color=green,mark=diamond*,mark size=1.5,thick] table{results/th_gom.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{Prediction accuracy of different methods vs the maximum tolerated absolute error with $\Phi=10$ and $\Omega=6$.}
	\label{fig:real}
\end{figure}

In the final experiment, we investigated for what fraction of test samples a model can have a lower prediction error than a threshold. In other words, to evaluate the prediction accuracy of a model, we record the fraction of test samples for which the difference between their true times and the predicted ones are lower than a given threshold, called \emph{tolerated error}. To this end, we again used the median as the predicted value by all models that were trained using our dynamic features. The feature extraction and observation windows were set to 10 and 6, respectively, and the results for different tolerated errors in range $\{0.5, 1.0, \dots, 3.0\}$ were plotted in Fig~\ref{fig:real}. The result demonstrates that \npglm can achieve a higher accuracy in all cases relative to other baselines, especially when dealing with lower tolerated errors.

\begin{table*}[t]
	\centering
	\caption{Performance Comparison of Different Methods Under Different Lengths for Observation Window when $\Phi=10$}
	\label{table:results}
	\scriptsize
	\begin{tabu} to \textwidth {X[l] c l X[c] X[c] c X[c] X[c] c X[c] X[c]}
		\toprule
		& & 
		& \multicolumn{2}{c}{$\Omega=3$} & & \multicolumn{2}{c}{$\Omega=6$} & & \multicolumn{2}{c}{$\Omega=9$}\\
		\cmidrule(l){4-5} \cmidrule{7-8} \cmidrule{10-11}
		%\cmidrule(l){2-3} \cmidrule{5-7}
		Dataset & Feature &
		Model & MAE & MRE & & MAE & MRE & & MAE & MRE\\
		\midrule
		\multirow{8}{*}{dblp-db}
		& \multirow{4}{*}{\rotatebox{90}{Dynamic}}
		& \npglm & $\bm{0.21\pm0.02}$ & $\bm{0.16\pm0.07}$ & & $\bm{0.76\pm0.05}$ & $\bm{0.34\pm0.03}$ & & $\bm{1.10\pm0.09}$ & $\bm{0.43\pm0.02}$ \\
		& & \textsc{Exp-Glm} & $0.27\pm0.09$ & $0.20\pm0.02$ & & $0.83\pm0.09$ & $0.43\pm0.06$ & & $1.39\pm0.04$ & $0.66\pm0.01$ \\
		& & \textsc{Ray-Glm} & $0.40\pm0.04$ & $0.32\pm0.05$ & & $1.90\pm0.06$ & $1.00\pm0.09$ & & $2.56\pm0.01$ & $1.60\pm0.02$ \\
		& & \textsc{Gom-Glm} & $0.38\pm0.09$ & $0.32\pm0.09$ & & $1.89\pm0.07$ & $1.23\pm0.02$ & & $3.30\pm0.07$ & $2.03\pm0.01$ \\
		
		\cmidrule{2-11}
		& \multirow{4}{*}{\rotatebox{90}{Static}}
		& \npglm & $0.27\pm0.01$ & $0.20\pm0.01$ & & $0.85\pm0.03$ & $0.45\pm0.02$ & & $1.32\pm0.07$ & $0.56\pm0.02$ \\
		& & \textsc{Exp-Glm} & $0.33\pm0.01$ & $0.24\pm0.01$ & & $0.93\pm0.03$ & $0.51\pm0.02$ & & $1.54\pm0.06$ & $0.74\pm0.05$ \\
		& & \textsc{Ray-Glm} & $0.48\pm0.02$ & $0.37\pm0.02$ & & $2.16\pm0.06$ & $1.30\pm0.04$ & & $3.37\pm0.12$ & $1.84\pm0.11$ \\
		& & \textsc{Gom-Glm} & $0.48\pm0.01$ & $0.36\pm0.01$ & & $2.28\pm0.02$ & $1.37\pm0.03$ & & $4.24\pm0.10$ & $2.28\pm0.06$ \\
		
		\midrule
		\multirow{8}{*}{dblp-th}
		& \multirow{4}{*}{\rotatebox{90}{Dynamic}}
		& \npglm & $\bm{0.22\pm0.03}$ & $\bm{0.17\pm0.08}$ & & $\bm{0.75\pm0.09}$ & $\bm{0.36\pm0.02}$ & & $\bm{1.06\pm0.09}$ & $\bm{0.47\pm0.08}$ \\
		& & \textsc{Exp-Glm} & $0.30\pm0.03$ & $0.19\pm0.07$ & & $0.75\pm0.09$ & $0.43\pm0.06$ & & $1.37\pm0.03$ & $0.60\pm0.02$ \\
		& & \textsc{Ray-Glm} & $0.41\pm0.01$ & $0.34\pm0.01$ & & $1.83\pm0.06$ & $1.11\pm0.02$ & & $3.01\pm0.07$ & $1.56\pm0.04$ \\
		& & \textsc{Gom-Glm} & $0.38\pm0.06$ & $0.30\pm0.09$ & & $1.88\pm0.05$ & $1.23\pm0.02$ & & $3.97\pm0.06$ & $2.14\pm0.02$ \\
		
		\cmidrule{2-11}
		& \multirow{4}{*}{\rotatebox{90}{Static}}
		& \npglm & $0.28\pm0.01$ & $0.21\pm0.01$ & & $0.89\pm0.04$ & $0.47\pm0.02$ & & $1.37\pm0.07$ & $0.57\pm0.03$ \\
		& & \textsc{Exp-Glm} & $0.34\pm0.02$ & $0.25\pm0.02$ & & $0.98\pm0.03$ & $0.54\pm0.02$ & & $1.59\pm0.07$ & $0.77\pm0.04$ \\
		& & \textsc{Ray-Glm} & $0.50\pm0.03$ & $0.39\pm0.02$ & & $2.26\pm0.07$ & $1.36\pm0.05$ & & $3.54\pm0.13$ & $1.92\pm0.08$ \\
		& & \textsc{Gom-Glm} & $0.50\pm0.01$ & $0.38\pm0.02$ & & $2.38\pm0.06$ & $1.43\pm0.07$ & & $4.41\pm0.14$ & $2.40\pm0.07$ \\
		
		\bottomrule
	\end{tabu}
\end{table*}
