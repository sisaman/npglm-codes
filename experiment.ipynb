{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "from progressbar import *\n",
    "from models import Model\n",
    "from models.ExpGlm import ExpGlm\n",
    "from models.WblGlm import WblGlm\n",
    "from models.NpGlm import NpGlm\n",
    "from models.RayGlm import RayGlm\n",
    "from features.delicious.extraction import run as delicious_feature\n",
    "from features.movielens.extraction import run as movielens_feature\n",
    "from features.dblp.extraction import run as dblp_feature\n",
    "from features.utils import timestamp_delta_generator\n",
    "from features.autoencoder import encode\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dist):\n",
    "    return {\n",
    "        'np': NpGlm(),\n",
    "        'wbl': WblGlm(),\n",
    "        'exp': ExpGlm(),\n",
    "        'ray': RayGlm(),\n",
    "    }[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_c_index(T_true, T_pred, Y):\n",
    "    total_number_of_pairs = 0\n",
    "    number_of_correct_predictions = 0\n",
    "\n",
    "    for i in range(len(T_true)):\n",
    "        for j in range(len(T_true) - 1, i, -1):\n",
    "            if Y[i] != 0 or Y[j] != 0:  # if one or both of the samples are in observation window\n",
    "                total_number_of_pairs += 1\n",
    "                if T_true[i] > T_true[j] and T_pred[i] > T_pred[j]:\n",
    "                    number_of_correct_predictions += 1\n",
    "                if T_true[i] < T_true[j] and T_pred[i] < T_pred[j]:\n",
    "                    number_of_correct_predictions += 1\n",
    "                if T_true[i] == T_true[j] and T_pred[i] == T_pred[j]:\n",
    "                    number_of_correct_predictions += 1\n",
    "\n",
    "    return number_of_correct_predictions / total_number_of_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, Y, T, convert_to_month=False):\n",
    "    T = T.astype(np.float64)\n",
    "    if convert_to_month:\n",
    "        T /= timestamp_delta_generator(months=1)\n",
    "    T += np.random.rand(len(T)) * Y\n",
    "\n",
    "    index = np.argsort(T, axis=0).ravel()\n",
    "    X = X[index, :]\n",
    "    Y = Y[index]\n",
    "    T = T[index]\n",
    "\n",
    "    return X, Y, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: Model, X_train: np.ndarray, Y_train: np.ndarray, T_train: np.ndarray, X_test: np.ndarray,\n",
    "             Y_test: np.ndarray, T_test: np.ndarray, acc_thresholds):\n",
    "    model.fit(X_train, Y_train, T_train)\n",
    "    T_pred = model.quantile(X_test, .5).ravel()\n",
    "    c_index = generate_c_index(T_test, np.fmin(T_pred, max(T_test)), Y_test)\n",
    "\n",
    "    k = Y_test.sum()\n",
    "    T_test = T_test[:k]\n",
    "    T_pred = T_pred[:k]\n",
    "\n",
    "    res = np.abs(T_pred - T_test)\n",
    "\n",
    "    distance = np.zeros((len(acc_thresholds)))\n",
    "    for i in range(len(acc_thresholds)):\n",
    "        distance[i] = (res <= acc_thresholds[i]).sum() / len(res)\n",
    "\n",
    "    mae = mean_absolute_error(T_test, T_pred)\n",
    "    rmse = mean_squared_error(T_test, T_pred) ** .5\n",
    "    msle = mean_squared_log_error(T_test, T_pred)\n",
    "    mre = (res / T_test).mean()\n",
    "    mad = median_absolute_error(T_test, T_pred)\n",
    "\n",
    "    return (mae, mre, rmse, msle, mad, c_index) + tuple(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(dists, X_stat, X, Y, T, cv, acc_thresholds):\n",
    "    threads = []\n",
    "    results = {dist+pos: [] for dist in dists for pos in ['', '_stat']}\n",
    "    k_fold = StratifiedKFold(n_splits=cv, shuffle=True)\n",
    "\n",
    "    widget = [Bar('=', '[', ']'), ' ', Percentage()]\n",
    "    bar = ProgressBar(maxval=cv*len(dists)*2, widgets=widget)\n",
    "    \n",
    "    for training_indices, test_indices in k_fold.split(X=X, y=Y):\n",
    "        X_stat_train = X_stat[training_indices, :]\n",
    "        X_train = X[training_indices, :]\n",
    "        Y_train = Y[training_indices]\n",
    "        T_train = T[training_indices]\n",
    "\n",
    "        X_stat_test = X_stat[test_indices, :]\n",
    "        X_test = X[test_indices, :]\n",
    "        Y_test = Y[test_indices]\n",
    "        T_test = T[test_indices]\n",
    "\n",
    "        def worker():\n",
    "            for dist in dists:\n",
    "                model = get_model(dist)\n",
    "                scores = evaluate(model, X_train, Y_train, T_train, X_test, Y_test, T_test, acc_thresholds)\n",
    "                results[dist].append(scores)\n",
    "                bar.update(bar.currval+1)\n",
    "                scores_stat = evaluate(model, X_stat_train, Y_train, T_train, X_stat_test, Y_test, T_test, acc_thresholds)\n",
    "                results[dist+'_stat'].append(scores_stat)\n",
    "                bar.update(bar.currval+1)\n",
    "\n",
    "        job = threading.Thread(target=worker)\n",
    "        threads.append(job)\n",
    "        \n",
    "    bar.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    \n",
    "    bar.finish()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(dist):\n",
    "    return {\n",
    "        'np': 'NP-Glm',\n",
    "        'wbl': 'Wbl-Glm',\n",
    "        'exp': 'Exp-Glm',\n",
    "        'ray': 'Ray-Glm',\n",
    "    }[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_list, Y_raw, T_raw = dblp_feature(delta=1, observation_window=6, n_snapshots=3)\n",
    "# X_list, Y_raw, T_raw = delicious_feature(delta=1, observation_window=6, n_snapshots=9)\n",
    "# X_list, Y_raw, T_raw = movielens_feature(delta=1, observation_window=6, n_snapshots=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 4000\n",
    "if len(Y_raw) > limit:\n",
    "    X = np.stack(X_list, axis=1)  # X.shape = (n_samples, timesteps, n_features)\n",
    "    X, _, Y_raw, _, T_raw, _ = train_test_split(X, Y_raw, T_raw, train_size=limit, stratify=Y_raw, shuffle=True)\n",
    "    for i in range(len(X_list)):\n",
    "        X_list[i] = X[:,i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_raw = encode(X_list, epochs=100, latent_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "X, Y, T = prepare_data(X_raw, Y_raw, T_raw)\n",
    "scaler = MinMaxScaler(copy=True)\n",
    "X_stat = scaler.fit_transform(X_list[0])\n",
    "\n",
    "dists = [\n",
    "    'np',\n",
    "    'wbl',\n",
    "    'exp',\n",
    "    'ray',\n",
    "]\n",
    "\n",
    "print(len(T))\n",
    "\n",
    "results = cross_validate(dists, X_stat, X, Y, T, cv=5, acc_thresholds=[i/2 for i in range(1,7)])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "table = []\n",
    "row = []\n",
    "header = ['MAE', 'MRE', 'RMSE', 'MSLE', 'MDAE', 'CI', 'ACC-1', 'ACC-2', 'ACC-3', 'ACC-4', 'ACC-5', 'ACC-6']\n",
    "for pos in ['', '_stat']:\n",
    "    for dist in dists:\n",
    "        row.append(get_name(dist)+pos)\n",
    "        result = np.array(results[dist+pos])\n",
    "        mean = result.mean(axis=0)\n",
    "        table.append(mean)\n",
    "print(tabulate(table, showindex=row, floatfmt=\".2f\", headers=header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
