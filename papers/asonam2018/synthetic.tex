\section{Synthetic Evaluations}\label{sec:synthetic}
We use synthetic data to verify the correctness of \npglm and its learning algorithm. Since \npglm is a non-parametric method, we generate synthetic data using various parametric models with previously known random parameters, and evaluate how well \npglm can learn the parameters and the underlying distribution of the generated data.

\subsection{Experiment Setup}
We consider generalized linear models of two widely used distributions for event-time modeling, Rayleigh and Gompertz, as the ground truth models for generating synthetic data. Algorithm~\ref{alg:syn} is used to generate a total of $N$ data samples with $d$-dimensional feature vectors, consisting $N_o$ non-censored (observed) samples and remaining $N_c=N-N_o$ censored ones. For all synthetic experiments, we generate 10-dimensional feature vectors ($d=10$) and set $g(\mb{w}^T\mb{x})=\exp(\mb{w}^T\mb{x})$. We repeat every experiment 100 times and report the average results.

\begin{algorithm}[t]
	\small
	\SetAlgoLined
	\KwIn{The number of observed samples $N_o$, the number of censored samples $N_c$, the dimension of the feature vectors $d$, and the desired distribution $dist$}
	\KwOut{Synthetically generated data $\mb{X}_{N\times d}$, $\mb{y}_{N\times1}$, and $\mb{t}_{N\times1}$.}
	$N\leftarrow N_o+N_c$\;
	Draw a weight vector $\mb{w}\sim\mathcal{N}(0,\mb{I}_d)$, where $\mb{I}_d$ is the $d$-dimensional identity matrix\;
	Draw scalar intercept $b\sim\mathcal{N}(0,1)$\;
	\For{$i\leftarrow1$ to $N$}{
		Draw feature vector $\mb{x}_i\sim\mathcal{N}(0,\mb{I}_d)$\;
		Set distribution parameter $\alpha_i\leftarrow\exp(\mb{w}^T\mb{x}_i+b)$\;
		\uIf{$dist == Rayleigh$}{
			Draw $t_i\sim\alpha_i~t\exp\{-0.5\alpha_it^2\}$\;
		}
		\uElseIf{$dist == Gompertz$}{
			Draw $t_i\sim\alpha_i~e^t\exp\{-\alpha_i(e^t-1)\}$\;
		}
	}
	
	Sort pairs $(\mb{x}_i,t_i)$ by $t_i$ in ascending order\;
	
	\For{$i\leftarrow1$ to $N_o$}{
		$y_i\leftarrow1$\;
	}
	\For{$i\leftarrow(N_o+1)$ to $N$}{
		$y_i\leftarrow0$\;
	}
	\caption{Synthetic dataset generation algorithm.}
	\label{alg:syn}
\end{algorithm}


\subsection{Experiment Results}
Since \npglm's learning is done in an iterative manner, we first analyze whether this algorithm converges as the number of iterations increases. We recorded the log-likelihood of \npglm, averaged over the number of training samples $N$ in each iteration. We repeated this experiment for $N\in\{1000,2000,3000\}$ with a fixed censoring ratio of 0.5, which means half of the samples are censored. The result is depicted in Fig.~\ref{fig:syn-cvg-n}. We can see that the algorithm successfully converges with a rate depending on the underlying distribution. For the case of Rayleigh, it requires about 100 iterations to converge but for Gompertz, this reduces to about 30. Also, we see that using more training data leads to achieving more log-likelihood as expected.



In Fig.~\ref{fig:syn-cvg-c}, we fixed $N=1000$ and performed the same experiment this time using different censoring ratios. According to the figure, we see that by increasing the censoring ratio, the convergence rate increases. This is because \npglm infers the values of $H(t)$ for all $t$ in the observation window. Therefore, as the censoring ratio increases, the observation window is decreased, so \npglm has to infer a fewer number of parameters, leading to a faster convergence. Note that as opposed to Fig.~\ref{fig:syn-cvg-n}, here a higher log-likelihood doesn't necessarily indicate a better fit, due to the likelihood marginalization we get by censored samples.


%Next, we analyzed the performance of \npglm in terms of the achieved log-likelihood on a separate test dataset by gradually increasing the number of training samples under different censoring ratios. We put away a number of 100K synthetically generated test data samples and trained \npglm with a training dataset of size ranging from 100 to 900. In each step, we calculated the average log-likelihood of the trained model on the test. We repeated this experiment using different censoring ratios. The result is depicted in Fig.~\ref{fig:syn-logl-n}. According to the figure, the log-likelihood achieved on the test dataset gradually rises with the increase in the number of training samples. That is because using more training samples could result in a better estimate of the parameters by which the test data samples are generated.

Next, we evaluated how good \npglm can infer the parameters used to generate synthetic data. To this end, we varied the number of training samples $N$ and measured the mean absolute error (MAE) between the learned weight vector $\hat{\mathbf{w}}$ and the ground truth. Fig.~\ref{fig:syn-mae-n} illustrates the result for different censoring ratios. It can be seen that as the number of training samples increases, the MAE gradually decreases. The other point to notice is that more censoring ratio results in higher error due to the information loss we get by censoring.



Finally, we investigated whether censored samples are informative or not. For this purpose, we fixed the number of observed samples $N_o$ and changed the number of censored samples from 0 to 200. We measured the MAE between the learned $\mb{w}$ and the ground truth for $N_o\in\{200,300,400\}$. The result is shown in Fig.~\ref{fig:syn-mae-c}. It clearly demonstrates that adding more censored samples causes the MAE to dwindle up to an extent, after which we get no substantial improvement. This threshold is dependent on the underlying distribution. In this case, for Rayleigh and Gompertz it is about 80 and 120, respectively.

\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		ymax=2.5,
		ymin=1.2,
		xmin=0,
		xmax=200,
		%ytick={0.08,0.10,...,0.2},
		xtick={20,60,...,180},
		restrict x to domain=0:200,
		legend entries={${\tiny N=1000}$, $N=2000$, $N=3000$},
		]
		\addplot[color=cyan,  thick, dashed] table{results/cvg_ray_1000.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_ray_2000.txt};
		\addplot[color=purple,thick] table{results/cvg_ray_3000.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		ymax=2.3,
		%ymin=0.06,
		xmin=0,
		xmax=60,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,20,...,50},
		restrict x to domain=0:100,
		legend entries={$N=1000$, $N=2000$, $N=3000$},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_gom_1000.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_gom_2000.txt};
		\addplot[color=purple,thick] table{results/cvg_gom_3000.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{Convergence of \npglm's average log-likelihood ($\log\mathcal{L}$) for different number of training samples ($N$). Censoring ratio has been set to 0.5.}
	\label{fig:syn-cvg-n}
\end{figure}
\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -8 pt,
		%ymax=0.2,
		ymin=-2,
		xmin=0,
		xmax=100,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,30,...,90},
		restrict x to domain=0:200,
		legend entries={5\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_ray_5.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_ray_25.txt};
		\addplot[color=purple,thick] table{results/cvg_ray_50.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=south east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		xmajorgrids,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=1,
			/tikz/.cd
		},
		xlabel=$Iteration$,
		%xticklabel style={rotate=90},
		ylabel=$\log\mathcal{L}$,
		ylabel shift = -4 pt,
		%ymax=0.2,
		%ymin=0.06,
		xmin=0,
		xmax=60,
		%ytick={0.08,0.10,...,0.2},
		xtick={10,20,...,50},
		restrict x to domain=0:60,
		legend entries={5\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=cyan  ,thick, dashed] table{results/cvg_gom_5.txt};
		\addplot[color=orange,ultra thick, dotted] table{results/cvg_gom_25.txt};
		\addplot[color=purple,thick] table{results/cvg_gom_50.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{Convergence of \npglm's average log-likelihood ($\log\mathcal{L}$) for different censoring ratios with 1K samples.}
	\label{fig:syn-cvg-c}
\end{figure}

%\begin{figure}[t]
%	\hfill  
%	\subfloat[Rayleigh distribution]{
%		\begin{tikzpicture}[trim axis left, trim axis right]
%		\begin{axis}
%		[
%		tiny,
%		width=0.56\columnwidth,
%		height=4.5cm,
%		legend pos=south east,
%		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
%		grid,
%		y tick label style={
%			/pgf/number format/.cd,
%			fixed,
%			fixed zerofill,
%			precision=1,
%			/tikz/.cd
%		},
%		xlabel=$ N $,
%		ylabel=$\log\mathcal{L}$,
%		ylabel shift = -4 pt,
%		%xticklabel style={rotate=90},
%		%		ymax=0.35,
%		xmin=0,
%		xmax=1000,
%		%		ytick={0.05,0.10,...,0.35},
%		xtick={100,300,...,900},
%		restrict x to domain=0:900,
%		legend entries={0\% censoring, 5\% censoring, 10\% censoring},
%		]
%		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/logl_ray_0.txt};
%		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/logl_ray_5.txt};
%		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/logl_ray_10.txt};
%		\end{axis}
%		\end{tikzpicture}
%	}\hspace{1cm}
%	\subfloat[Gompertz distribution]{
%		\begin{tikzpicture}[trim axis left, trim axis right]
%		\begin{axis}
%		[
%		tiny,
%		width=0.56\columnwidth,
%		height=4.5cm,
%		legend pos=south east,
%		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
%		grid,
%		y tick label style={
%			/pgf/number format/.cd,
%			fixed,
%			fixed zerofill,
%			precision=1,
%			/tikz/.cd
%		},
%		xlabel=$ N $,
%		%xticklabel style={rotate=90},
%		ylabel=$\log\mathcal{L}$,
%		ylabel shift = -4 pt,
%		%		ymax=0.22,
%		%		ymin=0.01,
%		xmin=0,
%		xmax=1000,
%		xtick={100,300,...,900},
%		restrict x to domain=0:900,
%		%		ytick={0.04,0.07,...,0.21},
%		legend entries={0\% censoring, 5\% censoring, 10\% censoring},
%		]
%		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/logl_gom_0.txt};
%		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/logl_gom_5.txt};
%		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/logl_gom_10.txt};
%		\end{axis}
%		\end{tikzpicture}
%	}
%	\caption{\npglm's achieved average log-likelihood on the separate test data vs the number of training samples ($N$) with different censoring ratios.}
%	\label{fig:syn-logl-n}
%\end{figure}

\begin{figure}[t]
	\hfill  
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$ N $,
		ylabel=MAE,
		ylabel shift = -4 pt,
		%xticklabel style={rotate=90},
		ymax=0.35,
		xmin=0,
		xmax=1000,
		ytick={0.05,0.10,...,0.35},
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		legend entries={0\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_ray.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_ray_25.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_ray_50.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$ N $,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.22,
		ymin=0.01,
		xmin=0,
		xmax=1000,
		xtick={100,300,...,900},
		restrict x to domain=0:900,
		ytick={0.04,0.07,...,0.21},
		legend entries={0\% censoring, 25\% censoring, 50\% censoring},
		]
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_gom.txt};
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_gom_25.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_gom_50.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{\npglm's mean absolute error (MAE) vs the number of training samples ($N$) for different censoring ratios.}
	\label{fig:syn-mae-n}
\end{figure}

\begin{figure}[t]
	\hfill
	\subfloat[Rayleigh distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$N_c$,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.2,
		ymin=0.06,
		%xmin=0,
		%xmax=2100,
		ytick={0.08,0.10,...,0.2},
		xtick={0,40,...,200},
		legend entries={$N_o=200$, $N_o=300$, $N_o=400$},
		]
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_ray_200.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_ray_300.txt};
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_ray_400.txt};
		\end{axis}
		\end{tikzpicture}
	}\hspace{1cm}    
	\subfloat[Gompertz distribution]{
		\begin{tikzpicture}[trim axis left, trim axis right]
		\begin{axis}
		[
		tiny,
		width=0.56\columnwidth,
		height=4.5cm,
		legend pos=north east,
		legend style={font=\scriptsize,nodes={scale=0.75, transform shape}},
		grid,
		y tick label style={
			/pgf/number format/.cd,
			fixed,
			fixed zerofill,
			precision=2,
			/tikz/.cd
		},
		xlabel=$N_c$,
		%xticklabel style={rotate=90},
		ylabel=MAE,
		ylabel shift = -4 pt,
		ymax=0.24,
		ymin=0.03,
		%xmin=0,
		%xmax=2100,
		ytick={0.06,0.09,...,0.21},
		xtick={0,40,...,200},
		legend entries={$N_o=200$, $N_o=300$, $N_o=400$},
		]
		\addplot[color=cyan,mark=*,mark size=1.1,thick] table{results/mae_gom_200.txt};
		\addplot[color=orange,mark=triangle*,mark size=1.5,thick] table{results/mae_gom_300.txt};
		\addplot[color=purple,mark=square*,mark size=1.1,thick] table{results/mae_gom_400.txt};
		\end{axis}
		\end{tikzpicture}
	}
	\caption{\npglm's mean absolute error (MAE) vs the number of censored samples ($N_c$) for different number of observed samples ($N_o$).}
	\label{fig:syn-mae-c}
\end{figure}
