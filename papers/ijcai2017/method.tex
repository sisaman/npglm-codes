\section{Proposed Method}\label{sec:method}
In this section we introduce our proposed model, called \emph{Non-Parametric Generalized Linear Model}, to solve the problem of temporal link prediction. As we talked about in previous sections, we are going to model the distribution $f_T(t\mid x)$ so that we can answer the time-related queries using the feature vector $x$ for a missing link in the network. The recent approach \cite{sun2012will} has considered a specific distribution for $t$ (e.g. Exponential distribution) and then related $x$ to $t$ using a Generalized Linear Model. The major drawback of this approach is that we need to know the exact distribution of time, or at least, we could guess the best one that fits. The alternative way that we follow is to learn the shape of $f_T(t\mid~x)$ from the data using a non-parametric solution.

\subsection{Model Description}
Looking at the Eq.~\ref{eq:intensity}, we see that the density function can be specified uniquely with its intensity function. Since the intensity function often has a simpler form than the density itself, if we learn the shape of the intensity function, then we can infer the entire distribution eventually. Therefore, we focus on learning the shape of the conditional intensity function $\lambda(t\mid x)$ from the data, and then accordingly infer the conditional density function $f_T(t\mid x)$ based on the learned intensity.
In order to reduce the hypothesis space of the problem and avoid the curse of dimensionality, we assume that $\lambda(t\mid x)$, which is a function of both $t$ and $x$, can be factorized into two separate positive functions as the following:
\begin{equation}\label{eq:lambda}
\lambda(t\mid x)=g(w^Tx)h(t)
\end{equation}
where $g$ is a functions of $x$ which captures the effect of features via a linear transformation using coefficient vector $w$ independent of $t$, and $h$ is a function of $t$ which captures the effect of time independent from $x$. This assumption, referred to as proportional hazards condition \cite{breslow1975analysis}, holds in GLM formulations of many event-time modeling distributions, such as Exponential, Rayleigh, Power-Law, and so on. Our goal is now to fix the function $g$ and learn the coefficient vector $w$ and the function $h$ from the training data. We begin by the likelihood function of the data which is as follows:

\begin{equation}
\prod_{i=1}^{N}f_T(t_i\mid x_i)^{y_i}P(T\ge t_i\mid x_i)^{1-y_i}\\
\end{equation}
The likelihood consists of the product of two parts: The first part is the contribution of those samples for which we have seen their exact formation time in terms of their density function. The second part on the other hand, is the contribution of the censored samples. For these samples, we use the probability of the formation time being greater than the recorded one. Applying the Eq.~\ref{eq:intensity}, \ref{eq:reliability}, and \ref{eq:lambda}, the likelihood function becomes:
\begin{equation}
\prod_{i=1}^{N}\left[g(w^Tx_i)h(t_i)\right]^{y_i}\exp\lbrace-g(w^Tx_i)\int_{0}^{t_i}h(t)dt\rbrace
\end{equation}

Since we don't know the form of $h(t)$, we cannot directly calculate the integral appeared in the likelihood function. To deal with this problem, we approximate $h(t)$ with a piecewise constant function that changes just in $t_i$ s. Therefore, the integral over $h(t)$, denoted by $H(t)$, becomes a series:
\begin{equation}\label{eq:cumh}
H(t_i)=\int_{0}^{t_i}h(t)dt \simeq \sum_{j=1}^{i}h(t_j)(t_j-t_{j-1})
\end{equation}
assuming samples are sorted by $t$ in increasing order, without loss of generality. The function $H(t)$ defined above plays an important role in both learning and inference phases. In fact, both the learning and inference phases rely on $H(t)$ instead of $h(t)$, which we will see later in this paper.
Replacing the above series in the likelihood, we end up with the following log-likelihood function:

\begin{equation}\label{eq:logl}
\begin{split}
\log\mathcal{L}
=\sum_{i=1}^{N}\Big\lbrace& y_i\left[\log g(w^Tx_i) + \log h(t_i)\right]\\&-g(w^Tx_i)\sum_{j=1}^{i}h(t_j)(t_j-t_{j-1})\Big\rbrace\\
\end{split}
\end{equation}

The log-likelihood function depends on the vector $w$ and the function $h(t)$. In the next part, we explain an iterative learning algorithm to learn both $w$ and $h$ collectively.

\subsection{Learning Algorithm}
Maximizing the log-likelihood function (Eq.~\ref{eq:logl}) rely on the choice of the function $g$. There are no particular limits on the choice of $g$ except that it must be a non-negative function. For example, both quadratic and exponential functions of $w^Tx$ will do the trick. Here, we proceed with $g(w^Tx)=\exp(w^Tx)$ since it yields a convex optimization function with respect to $w$. Subsequent equations can be derived for other choices of $g$ in the same way.

Setting the log-likelihood derivative with respect to $h(t_k)$ to zero, yields a closed form solution for $h(t_k)$:
\begin{equation}
h(t_k)=\frac{y_k}{(t_k-t_{k-1})\sum_{i=k}^{N}\exp(w^Tx_i)}
\end{equation}

Applying Eq.~\ref{eq:cumh}, we get the following for $H(t_i)$:
\begin{equation}
H(t_i)=\sum_{j=1}^{i}\frac{y_j}{\sum_{k=j}^{N}\exp(w^Tx_k)}
\end{equation}
which depends on the vector $w$. On the other hand, we cannot obtain a closed form solution for $w$ from the log-likelihood function. Therefore, we turn to use Gradient-based optimization methods to find the optimal value of $w$. The negative log-likelihood function with respect to $w$, denoted by $NL(w)$ is as follows:

\begin{equation}\label{eq:nlw}
NL(w)=\sum_{i=1}^{N}\left\lbrace\exp(w^Tx_i)H(t_i)-y_iw^Tx_i\right\rbrace
\end{equation}
which depends on the function $H$. As the learning of both $w$ and $H$ depends on each other, they should be learned collectively. Here, we use an iterative algorithm to learn $w$ and $H$ alternatively. We begin with a random vector $w^{(0)}$. Then in each iteration $\tau$, we first update $H^{(\tau)}(t_i)$ via Eq.~\ref{eq:cumh} using $w^{(\tau-1)}$. Second, we optimize Eq.~\ref{eq:nlw} using the values of $H^{(\tau)}(t_i)$ to obtain $w^{(\tau)}$. We continue this procedure until convergence.


\subsection{Convergence Analysis}
To analyze the convergence of likelihood maximization, we look at the likelihood function close to the extreme point (which we denote with $w_e$). For the extreme point $\frac{\partial \log \mathcal{L}}{\partial w}$ vanishes so we have: 
\begin{equation}\label{eq:ext}
\sum_{i=1}^{i=N} y_ix_i=\sum_{i=1}^{i=N} exp(w_e^Tx_i)H(t_i)x_i
\end{equation}
Looking into the second derivative we have:
\begin{equation}\label{eq:dif2}
-\frac{\partial^2 \log \mathcal {L}}{\partial w^2}=\sum_{i=1}^{i=N} exp(w^Tx_i)H(t_i)x_ix_i^T
\end{equation}
So for points near the extreme point putting $w=w_e+\delta w$ (where $\delta w$ is small), neglecting the higher order terms with respect to $\delta w$ we have:
\begin{equation}
\log \mathcal{L}(\delta w)=\log \mathcal{L}(w_e)-\frac{1}{2}\delta w^TM\delta w + O(\delta w^3)
\end{equation}
Which is of a quadratic form with respect to $\delta w$ and $M$ is the second derivative (Equation \ref{eq:dif2}) measured at $w_e$. $M$ measures the curvature of $\log \mathcal{L}$ hyper-surface near the extreme point and it's spectral radius gives us a measure of how fast our maximization procedure converges to $w_e$. 
Without going through the maximization process we can establish a bound on $M$ (and thus convergence) by noting that amongst the $x_i$ we can find one (denoting it with $x_s$) such that:
\begin{equation}
M>=(\sum_{i=1}^{i=N} exp(w_e^Tx_i)H(t_i)x_i) x_s^T
\end{equation}
Comparing with (Equation \ref{eq:ext}) we can write the RHS as:
\begin{equation}
M_e=(\sum_{i=1}^{i=N} y_ix_i) x_s^T
\end{equation}
So our likelihood function converges to the extremum at a rate faster than a quadratic form with $M_e$.


\subsection{Inference and Sampling}
In this part, we come across answering the common inference queries and the method of sampling based on the inferred distribution $f_T(t\mid x)$. Suppose that we have learned the vector $\hat{w}$ and function $\hat{H}$ using the training samples $(x_i, y_i, t_i), i=1\dots N$. With this in mind, for a test link $l$ associated with a feature vector $x_l$, the following queries can be answered:\\


\descr{Ranged Probability.} What is the probability for the link $l$ to be formed between time $t_\alpha$ and $t_\beta$? This is equivalent to calculating $P(t_\alpha \le T \le t_\beta \mid x_l)$, which by definition is equal to:
\begin{equation}\label{eq:ranged}
\begin{split}
P(t_\alpha\le T \le t_\beta \mid x_l) = S(t_\alpha\mid x_l) - S(t_\beta\mid x_l)\\
= \exp\{-g(\hat{w}^Tx_l)\hat{H}(t_\alpha)\} - \exp\{-g(\hat{w}^Tx_l)\hat{H}(t_\beta)\}
\end{split}
\end{equation}
The problem here is to obtain the values of $\hat{H}(t_\alpha)$ and $\hat{H}(t_\beta)$, as $t_\alpha$ and $t_\beta$ may not be among $t_i$s of the training samples, for which $\hat{H}(.)$ is estimated. To calculate $\hat{H}(t_\alpha)$, we find $k\in\{1,2,\dots,N\}$ such that $t_k\le t_\alpha < t_{k+1}$. Due to the piecewise constant assumption for $h(.)$, we get:
\begin{equation}\label{eq:inf1}
\hat{h}(t_\alpha)=\frac{\hat{H}(t_\alpha)-\hat{H}(t_k)}{t_\alpha-t_k}
\end{equation} 
On the other hand, since $h(.)$ only changes in $t_i$s, we have:
\begin{equation}\label{eq:inf2}
\hat{h}(t_\alpha)=\hat{h}(t_{k+1})=\frac{\hat{H}(t_{k+1})-\hat{H}(t_k)}{t_{k+1}-t_k}
\end{equation}
Combining Eq.~\ref{eq:inf1} and \ref{eq:inf2}, we have:
\begin{equation}\label{eq:inf3}
\hat{H}(t_\alpha)=\hat{H}(t_k)+(t_\alpha-t_k)\frac{\hat{H}(t_{k+1})-\hat{H}(t_k)}{t_{k+1}-t_k}
\end{equation}
Following the similar approach, we can calculate $\hat{H}(t_\beta)$, and then answer the query using Eq.~\ref{eq:ranged}. The dominating operation here is to find the value of $k$. Since we have $t_i$s sorted beforehand, this operation can be done using a binary search with $O(\log N)$ time complexity.\\

\descr{Quantile.} By how long the link $l$ will be formed with probability $\alpha$? This question is equivalent to find the time $t_\alpha$ such that $P(T \le t_\alpha\mid x_l)=\alpha$. By definition, we have:
\begin{equation*}
\begin{split}
1-P(T \le t_\alpha\mid x_l)=S(t_\alpha\mid x_l)&=\exp\{-g(\hat{w}^Tx_l)\hat{H}(t_\alpha)\}\\
&=1-\alpha
\end{split}
\end{equation*}
Taking logarithm of both sides and rearranging, we get:
\begin{equation}\label{eq:inf4}
\hat{H}(t_\alpha)=-\frac{\log(1-\alpha)}{g(\hat{w}^Tx_l)}
\end{equation}
To find $t_\alpha$, we first find $k$ such that $\hat{H}(t_k)\le\hat{H}(t_\alpha)<\hat{H}(t_{k+1})$. We eventually have $t_k\le t_\alpha < t_{k+1}$ since $H(.)$ is a non-decreasing function due to the function $h$ being non-negative. Therefore, we again end up with Eq.~\ref{eq:inf3}, which by rearranging we get:
\begin{equation}\label{eq:inf5}
t_\alpha=(t_{k+1}-t_k)\frac{\hat{H}(t_\alpha)-\hat{H}(t_k)}{\hat{H}(t_{k+1})-\hat{H}(t_k)}+t_k
\end{equation}
By combining the Eq.~\ref{eq:inf4} and \ref{eq:inf5}, we can obtain the value of $t_\alpha$ which is the answer to the quantile query. It worth mentioning that if $\alpha=0.5$ then $t_\alpha$ becomes the median of the distribution $f_T(t\mid x_l)$. Here again the dominant operation is to find the value of $k$, which due to the non-decreasing property of $\hat{H}(.)$ can be found using a binary search with $O(\log N)$ time complexity.\\

\descr{Random Sampling.}
Generating random samples from the inferred distribution can easily be carried out using the Inverse-Transform sampling algorithm. To pick a random sample from the inferred distribution $f_T(t\mid x)$, we first generate uniform random variable $u\sim Uniform(0,1)$. Then, we find $k$ such that $S(t_{k+1}\mid x)\leq u\le S(t_k\mid x)$. We output $t_{k+1}$ as the generated sample. Again, searching for the suitable value of $k$ is the dominant operation which can be undertaken via binary search with $O(\log N)$ time complexity.

